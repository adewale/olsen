# Olsen Performance Analysis Tools

This directory contains Python scripts for analyzing performance statistics generated by the `--perfstats` flag during indexing.

## Prerequisites

```bash
python3
```

No additional dependencies required - uses only Python standard library.

## Available Tools

### 1. `compare_datasets.py`

Compare performance between two different indexing runs (e.g., small vs large dataset).

**Usage:**
```bash
python3 perftools/compare_datasets.py perfstats_small.json perfstats_large.json
```

**Output:**
- Dataset size comparison
- Pipeline stage breakdown (% of total time)
- Absolute timing changes
- Performance regression detection

**Example:**
```bash
python3 perftools/compare_datasets.py \
    perfstats_20251006_131024.json \
    perfstats_20251006_131939.json
```

### 2. `analyze_filetype.py`

Analyze performance for specific file types or patterns within a dataset.

**Usage:**
```bash
# Analyze by file extension
python3 perftools/analyze_filetype.py perfstats.json ".DNG"

# Analyze by pattern (substring matching)
python3 perftools/analyze_filetype.py perfstats.json "L10" --pattern

# Analyze JPEGs
python3 perftools/analyze_filetype.py perfstats.json ".jpeg"
```

**Output:**
- File count and total size
- Average timings per photo
- Pipeline stage breakdown
- Distribution statistics (min, median, P95, max)
- Variability analysis (coefficient of variation)

**Example:**
```bash
# Analyze Leica DNG performance
python3 perftools/analyze_filetype.py \
    perfstats_20251006_131939.json \
    "L10" --pattern
```

## Quick Reference: jq Queries

For quick analysis without running Python scripts:

```bash
# Get summary statistics
jq '.summary' perfstats.json

# Count photos by type
jq '.detailed | map(.FilePath | split("/")[-1] | split(".")[-1]) | group_by(.) | map({type: .[0], count: length})' perfstats.json

# Find slowest photos
jq -r '.detailed | sort_by(.TotalTime) | reverse | .[0:10] | .[] | "\(.TotalTime / 1000000 | floor)ms | \(.FilePath | split("/")[-1])"' perfstats.json

# Average time by stage
jq '.summary | {
  hash: .AvgHashMs,
  metadata: .AvgMetadataMs,
  decode: .AvgImageDecodeMs,
  thumbnails: .AvgThumbnailMs,
  color: .AvgColorMs,
  phash: .AvgPerceptualHashMs,
  database: .AvgDatabaseMs
}' perfstats.json

# Check for performance regressions
jq -r '.summary.AvgTotalMs' perfstats_new.json | \
  awk -v baseline=$(jq '.summary.AvgTotalMs' perfstats_baseline.json) \
      '{if ($1 > baseline * 1.2) print "REGRESSION: " ($1/baseline-1)*100 "% slower"}'
```

## Typical Workflows

### After Initial Indexing

1. Run indexing with performance tracking:
   ```bash
   ./bin/olsen index --db photos.db --w 4 --perfstats ~/Pictures
   ```

2. Analyze by file type to identify bottlenecks:
   ```bash
   python3 perftools/analyze_filetype.py perfstats_*.json ".DNG"
   python3 perftools/analyze_filetype.py perfstats_*.json ".jpeg"
   ```

3. Identify optimization priorities based on:
   - Which stage takes the most time (% of total)
   - Which stage has highest variability (CV %)
   - File type differences

### Performance Regression Testing

1. Establish baseline:
   ```bash
   ./bin/olsen index --db baseline.db --w 4 --perfstats testdata/dng
   cp perfstats_*.json baseline_perfstats.json
   ```

2. After code changes, run again:
   ```bash
   ./bin/olsen index --db new.db --w 4 --perfstats testdata/dng
   ```

3. Compare results:
   ```bash
   python3 perftools/compare_datasets.py baseline_perfstats.json perfstats_*.json
   ```

4. Check for regressions:
   - Total time per photo should not increase >10%
   - No single stage should show >20% increase
   - Throughput should not decrease >10%

### Optimization Impact Analysis

1. Before optimization:
   ```bash
   ./bin/olsen index --db before.db --w 4 --perfstats ~/Pictures
   mv perfstats_*.json before_perfstats.json
   ```

2. After optimization:
   ```bash
   ./bin/olsen index --db after.db --w 4 --perfstats ~/Pictures
   mv perfstats_*.json after_perfstats.json
   ```

3. Compare:
   ```bash
   python3 perftools/compare_datasets.py before_perfstats.json after_perfstats.json
   ```

4. Verify optimization achieved expected gains:
   - Target stage should show significant reduction
   - Total time should decrease proportionally
   - Other stages should be unaffected

## Understanding the Output

### Key Metrics

- **Total Time**: End-to-end processing time per photo
- **% of Total**: Percentage of time spent in each pipeline stage
- **Throughput**: MB/s of data processed (includes I/O)
- **CV (Coefficient of Variation)**: Measure of variability (higher = less consistent)

### Performance Targets

For production use (Leica DNG files, 70MB average):

| Metric | Target | Current (Baseline) |
|--------|--------|-------------------|
| Total time per photo | <2000ms | ~2700ms |
| Throughput | >30 MB/s | ~27 MB/s |
| Image decode % | <80% | ~89% |
| Color extract % | <5% | ~6% |

### Interpreting Results

**High % of Total** = Primary bottleneck
- Focus optimization efforts here first
- Even small improvements have large impact

**High CV %** = Inconsistent performance
- May indicate algorithmic issues (e.g., k-means iteration count)
- May indicate file-specific issues (corruption, complexity)

**Large P95-Median gap** = Outliers present
- Investigate slowest photos specifically
- May need special handling for edge cases

## Examples from Real Data

### Leica DNG Files (205 photos, 72MB avg)

```
Image Decode:    88.82% (2393ms avg) - PRIMARY BOTTLENECK
Color Extract:    5.94% (160ms avg)  - Acceptable
Thumbnails:       1.97% (53ms avg)   - Fast
Everything else:  <4%                - Negligible
```

**Conclusion**: RAW preview extraction is overwhelming bottleneck. Color and thumbnails are not issues.

### Mixed JPEG/DNG (1,189 photos)

```
Image Decode:    55.00% (422ms avg) - PRIMARY BOTTLENECK
Color Extract:   29.70% (228ms avg) - SECONDARY BOTTLENECK
Thumbnails:      11.34% (87ms avg)  - Acceptable
```

**Conclusion**: For JPEGs, color extraction becomes significant (70-80% of JPEG processing time).

### Small Synthetic Dataset (13 photos)

```
Thumbnails:      51.84% (605ms avg) - Misleading bottleneck!
Image Decode:    42.00% (490ms avg)
Color Extract:    4.43% (52ms avg)
```

**Conclusion**: Test data was NOT representative of production workload. Always test on real data!

## Troubleshooting

### "No photos found matching pattern"

- Check file extension case (use `.DNG` or `.dng` depending on files)
- Try pattern matching with `--pattern` flag
- Verify perfstats file contains detailed data

### Large memory usage

- The Python scripts load entire JSON into memory
- For >100MB JSON files, consider using `jq` for filtering first:
  ```bash
  jq '.detailed | map(select(.FilePath | contains("L10")))' perfstats.json > filtered.json
  python3 perftools/analyze_filetype.py filtered.json "L10" --pattern
  ```

### Inconsistent results

- Ensure system is not under other load during benchmarking
- Run multiple times and average results
- Check disk cache effects (first run vs subsequent runs)
- Monitor CPU temperature (thermal throttling)

## Contributing

When adding new analysis tools:

1. Follow existing naming convention: `verb_noun.py`
2. Include usage examples in docstring
3. Accept filename as first argument
4. Use argparse for command-line options
5. Output human-readable results to stdout
6. Update this README with usage examples
